### YamlMime:UniversalReference
ms.openlocfilehash: 496552af79989c144ce96db561de8b0882be0c21
ms.sourcegitcommit: 87f95d58ec8de16e115bc344efeb084afc346b74
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 08/12/2018
ms.locfileid: "40068845"
items:
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient
  name: ComputerVisionAPIClient
  fullName: ComputerVisionAPIClient
  children:
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.azureRegion
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.constructor
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.credentials
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResultWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModelsWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageWithHttpOperationResponse
  langs:
  - typeScript
  type: class
  summary: ''
  extends:
    name: ServiceClient
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage
  name: analyzeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.  All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire.  Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta."
  syntax:
    content: 'function analyzeImage(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_2
  name: analyzeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.  All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire.  Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta."
  syntax:
    content: 'function analyzeImage(url: string, options: function, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImage_1
  name: analyzeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.  All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire.  Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta."
  syntax:
    content: 'function analyzeImage(url: string, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain
  name: analyzeImageByDomain
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomain(model: string, url: string, options?: function)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Il contenuto specifico di dominio per riconoscere. I valori possibili sono: 'Celebrità', 'Riferimenti'
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_1
  name: analyzeImageByDomain
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomain(model: string, url: string, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomain_2
  name: analyzeImageByDomain
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomain(model: string, url: string, options: function, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream
  name: analyzeImageByDomainInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options?: function)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Il contenuto specifico di dominio per riconoscere.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_1
  name: analyzeImageByDomainInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStream_2
  name: analyzeImageByDomainInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options: function, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainInStreamWithHttpOperationResponse
  name: analyzeImageByDomainInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomainInStreamWithHttpOperationResponse(model: string, image: stream.Readable, options?: function)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Il contenuto specifico di dominio per riconoscere.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageByDomainWithHttpOperationResponse
  name: analyzeImageByDomainWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomainWithHttpOperationResponse(model: string, url: string, options?: function)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Il contenuto specifico di dominio per riconoscere. I valori possibili sono: 'Celebrità', 'Riferimenti'
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream
  name: analyzeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
  syntax:
    content: 'function analyzeImageInStream(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_1
  name: analyzeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
  syntax:
    content: 'function analyzeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStream_2
  name: analyzeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
  syntax:
    content: 'function analyzeImageInStream(image: stream.Readable, options: function, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageInStreamWithHttpOperationResponse
  name: analyzeImageInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
  syntax:
    content: 'function analyzeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.analyzeImageWithHttpOperationResponse
  name: analyzeImageWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.  All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire.  Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta."
  syntax:
    content: 'function analyzeImageWithHttpOperationResponse(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.azureRegion
  name: azureRegion
  fullName: azureRegion
  children: []
  langs:
  - typeScript
  type: property
  summary: ''
  syntax:
    content: 'azureRegion: string'
    return:
      type:
      - string
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.constructor
  name: ComputerVisionAPIClient
  children: []
  type: constructor
  langs:
  - typeScript
  summary: ''
  syntax:
    content: 'new ComputerVisionAPIClient(credentials: ServiceClientCredentials, azureRegion: string, options?: ServiceClientOptions)'
    parameters:
    - id: credentials
      type:
      - ServiceClientCredentials
      description: >
        Credenziali della sottoscrizione che lo identificano in modo univoco la sottoscrizione client.
    - id: azureRegion
      type:
      - string
      description: >
        Aree di Azure supportate per gli endpoint di servizi cognitivi. I valori possibili sono: 'westus', 'westeurope', 'southeastasia', 'eastus2', 'westcentralus', 'westus2', 'eastus', 'southcentralus', 'northeurope', 'eastasia', 'australiaeast', 'brazilsouth'
    - id: options
      type:
      - ServiceClientOptions
      description: ''
      optional: true
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.credentials
  name: credentials
  fullName: credentials
  children: []
  langs:
  - typeScript
  type: property
  summary: ''
  syntax:
    content: 'credentials: ServiceClientCredentials'
    return:
      type:
      - ServiceClientCredentials
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_1
  name: describeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImage(url: string, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage
  name: describeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImage(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImage_2
  name: describeImage
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImage(url: string, options: function, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream
  name: describeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImageInStream(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_1
  name: describeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStream_2
  name: describeImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImageInStream(image: stream.Readable, options: function, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageInStreamWithHttpOperationResponse
  name: describeImageInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.describeImageWithHttpOperationResponse
  name: describeImageWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImageWithHttpOperationResponse(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_1
  name: generateThumbnail
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta corretta contiene l'immagine di anteprima binario. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnail(width: number, height: number, url: string, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail_2
  name: generateThumbnail
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta corretta contiene l'immagine di anteprima binario. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnail(width: number, height: number, url: string, options: function, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnail
  name: generateThumbnail
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta corretta contiene l'immagine di anteprima binario. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnail(width: number, height: number, url: string, options?: function)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Larghezza dell'anteprima. Deve essere compreso tra 1 e 1024.

        Consigliati minimo pari a 50.
    - id: height
      type:
      - number
      description: >
        Altezza dell'anteprima. Deve essere compreso tra 1 e

        1024. Consigliati minimo pari a 50.
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream
  name: generateThumbnailInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta corretta contiene l'immagine di anteprima binario. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options?: function)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Larghezza dell'anteprima. Deve essere compreso tra 1 e 1024.

        Consigliati minimo pari a 50.
    - id: height
      type:
      - number
      description: >
        Altezza dell'anteprima. Deve essere compreso tra 1 e

        1024. Consigliati minimo pari a 50.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_1
  name: generateThumbnailInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta corretta contiene l'immagine di anteprima binario. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStream_2
  name: generateThumbnailInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta corretta contiene l'immagine di anteprima binario. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options: function, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailInStreamWithHttpOperationResponse
  name: generateThumbnailInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta corretta contiene l'immagine di anteprima binario. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnailInStreamWithHttpOperationResponse(width: number, height: number, image: stream.Readable, options?: function)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Larghezza dell'anteprima. Deve essere compreso tra 1 e 1024.

        Consigliati minimo pari a 50.
    - id: height
      type:
      - number
      description: >
        Altezza dell'anteprima. Deve essere compreso tra 1 e

        1024. Consigliati minimo pari a 50.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<stream.Readable>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.generateThumbnailWithHttpOperationResponse
  name: generateThumbnailWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta corretta contiene l'immagine di anteprima binario. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnailWithHttpOperationResponse(width: number, height: number, url: string, options?: function)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Larghezza dell'anteprima. Deve essere compreso tra 1 e 1024.

        Consigliati minimo pari a 50.
    - id: height
      type:
      - number
      description: >
        Altezza dell'anteprima. Deve essere compreso tra 1 e

        1024. Consigliati minimo pari a 50.
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<stream.Readable>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult
  name: getTextOperationResult
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa interfaccia viene utilizzata per ottenere il risultato dell'operazione di testo. L'URL per questa interfaccia deve essere recuperato dal campo 'Operation-Location' restituito dall'interfaccia di riconoscere il testo.
  syntax:
    content: 'function getTextOperationResult(operationId: string, options?: function)'
    parameters:
    - id: operationId
      type:
      - string
      description: >
        ID dell'operazione di testo restituito nella risposta del 'Riconosce scritta a mano testo'
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TextOperationResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_2
  name: getTextOperationResult
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa interfaccia viene utilizzata per ottenere il risultato dell'operazione di testo. L'URL per questa interfaccia deve essere recuperato dal campo 'Operation-Location' restituito dall'interfaccia di riconoscere il testo.
  syntax:
    content: 'function getTextOperationResult(operationId: string, options: function, callback: ServiceCallback<TextOperationResult>)'
    parameters:
    - id: operationId
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TextOperationResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResult_1
  name: getTextOperationResult
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa interfaccia viene utilizzata per ottenere il risultato dell'operazione di testo. L'URL per questa interfaccia deve essere recuperato dal campo 'Operation-Location' restituito dall'interfaccia di riconoscere il testo.
  syntax:
    content: 'function getTextOperationResult(operationId: string, callback: ServiceCallback<TextOperationResult>)'
    parameters:
    - id: operationId
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TextOperationResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.getTextOperationResultWithHttpOperationResponse
  name: getTextOperationResultWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa interfaccia viene utilizzata per ottenere il risultato dell'operazione di testo. L'URL per questa interfaccia deve essere recuperato dal campo 'Operation-Location' restituito dall'interfaccia di riconoscere il testo.
  syntax:
    content: 'function getTextOperationResultWithHttpOperationResponse(operationId: string, options?: function)'
    parameters:
    - id: operationId
      type:
      - string
      description: >
        ID dell'operazione di testo restituito nella risposta del 'Riconosce scritta a mano testo'
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels
  name: listModels
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione restituisce l'elenco di modelli specifici di dominio che sono supportati per l'API visione artificiale.  L'API supporta attualmente solo un modello specifico di dominio: un sistema di riconoscimento di celebrità. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function listModels(options?: function)'
    parameters:
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ListModelsResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_2
  name: listModels
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione restituisce l'elenco di modelli specifici di dominio che sono supportati per l'API visione artificiale.  L'API supporta attualmente solo un modello specifico di dominio: un sistema di riconoscimento di celebrità. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function listModels(options: function, callback: ServiceCallback<ListModelsResult>)'
    parameters:
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ListModelsResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModels_1
  name: listModels
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione restituisce l'elenco di modelli specifici di dominio che sono supportati per l'API visione artificiale.  L'API supporta attualmente solo un modello specifico di dominio: un sistema di riconoscimento di celebrità. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function listModels(callback: ServiceCallback<ListModelsResult>)'
    parameters:
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ListModelsResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.listModelsWithHttpOperationResponse
  name: listModelsWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione restituisce l'elenco di modelli specifici di dominio che sono supportati per l'API visione artificiale.  L'API supporta attualmente solo un modello specifico di dominio: un sistema di riconoscimento di celebrità. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function listModelsWithHttpOperationResponse(options?: function)'
    parameters:
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_1
  name: recognizePrintedText
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedText(detectOrientation: boolean, url: string, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText
  name: recognizePrintedText
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options?: function)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Possibilità di rilevare l'orientamento del testo nell'immagine. Con detectOrientation = true di OCR servizio prova a rilevare l'orientamento dell'immagine e correggere l'errore prima dell'ulteriore elaborazione (ad esempio, se è capovolto).
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedText_2
  name: recognizePrintedText
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options: function, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream
  name: recognizePrintedTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options?: function)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Possibilità di rilevare l'orientamento del testo nell'immagine. Con detectOrientation = true di OCR servizio prova a rilevare l'orientamento dell'immagine e correggere l'errore prima dell'ulteriore elaborazione (ad esempio, se è capovolto).
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_1
  name: recognizePrintedTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStream_2
  name: recognizePrintedTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options: function, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextInStreamWithHttpOperationResponse
  name: recognizePrintedTextInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedTextInStreamWithHttpOperationResponse(detectOrientation: boolean, image: stream.Readable, options?: function)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Possibilità di rilevare l'orientamento del testo nell'immagine. Con detectOrientation = true di OCR servizio prova a rilevare l'orientamento dell'immagine e correggere l'errore prima dell'ulteriore elaborazione (ad esempio, se è capovolto).
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizePrintedTextWithHttpOperationResponse
  name: recognizePrintedTextWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedTextWithHttpOperationResponse(detectOrientation: boolean, url: string, options?: function)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Possibilità di rilevare l'orientamento del testo nell'immagine. Con detectOrientation = true di OCR servizio prova a rilevare l'orientamento dell'immagine e correggere l'errore prima dell'ulteriore elaborazione (ad esempio, se è capovolto).
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText
  name: recognizeText
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l'URL che è necessario usare per l'operazione Ottieni risultato dell'operazione testo scritto a mano.
  syntax:
    content: 'function recognizeText(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_2
  name: recognizeText
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l'URL che è necessario usare per l'operazione Ottieni risultato dell'operazione testo scritto a mano.
  syntax:
    content: 'function recognizeText(url: string, options: function, callback: ServiceCallback<void>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeText_1
  name: recognizeText
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l'URL che è necessario usare per l'operazione Ottieni risultato dell'operazione testo scritto a mano.
  syntax:
    content: 'function recognizeText(url: string, callback: ServiceCallback<void>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream
  name: recognizeTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l'URL che è necessario usare per l'operazione Ottieni risultato dell'operazione testo scritto a mano.
  syntax:
    content: 'function recognizeTextInStream(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_1
  name: recognizeTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l'URL che è necessario usare per l'operazione Ottieni risultato dell'operazione testo scritto a mano.
  syntax:
    content: 'function recognizeTextInStream(image: stream.Readable, callback: ServiceCallback<void>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStream_2
  name: recognizeTextInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l'URL che è necessario usare per l'operazione Ottieni risultato dell'operazione testo scritto a mano.
  syntax:
    content: 'function recognizeTextInStream(image: stream.Readable, options: function, callback: ServiceCallback<void>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextInStreamWithHttpOperationResponse
  name: recognizeTextInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l'URL che è necessario usare per l'operazione Ottieni risultato dell'operazione testo scritto a mano.
  syntax:
    content: 'function recognizeTextInStreamWithHttpOperationResponse(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<void>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.recognizeTextWithHttpOperationResponse
  name: recognizeTextWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l'URL che è necessario usare per l'operazione Ottieni risultato dell'operazione testo scritto a mano.
  syntax:
    content: 'function recognizeTextWithHttpOperationResponse(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<void>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage
  name: tagImage
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImage(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_1
  name: tagImage
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImage(url: string, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImage_2
  name: tagImage
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImage(url: string, options: function, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream
  name: tagImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImageInStream(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_1
  name: tagImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImageInStream(image: stream.Readable, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStream_2
  name: tagImageInStream
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImageInStream(image: stream.Readable, options: function, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - function
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageInStreamWithHttpOperationResponse
  name: tagImageInStreamWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: function)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionAPIClient.tagImageWithHttpOperationResponse
  name: tagImageWithHttpOperationResponse
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImageWithHttpOperationResponse(url: string, options?: function)'
    parameters:
    - id: url
      type:
      - string
      description: "\n"
    - id: options
      type:
      - function
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
  package: azure-cognitiveservices-computervision
references:
- uid: Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: ImageAnalysis
    fullName: ImageAnalysis
    uid: azure-cognitiveservices-computervision.ImageAnalysis
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: ImageAnalysis
    fullName: ImageAnalysis
    uid: azure-cognitiveservices-computervision.ImageAnalysis
  - name: '>'
    fullName: '>'
- uid: Promise<azure-cognitiveservices-computervision.DomainModelResults>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: DomainModelResults
    fullName: DomainModelResults
    uid: azure-cognitiveservices-computervision.DomainModelResults
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: DomainModelResults
    fullName: DomainModelResults
    uid: azure-cognitiveservices-computervision.DomainModelResults
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: DomainModelResults
    fullName: DomainModelResults
    uid: azure-cognitiveservices-computervision.DomainModelResults
  - name: '>>'
    fullName: '>>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: ImageAnalysis
    fullName: ImageAnalysis
    uid: azure-cognitiveservices-computervision.ImageAnalysis
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.ImageDescription>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: ImageDescription
    fullName: ImageDescription
    uid: azure-cognitiveservices-computervision.ImageDescription
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: ImageDescription
    fullName: ImageDescription
    uid: azure-cognitiveservices-computervision.ImageDescription
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: ImageDescription
    fullName: ImageDescription
    uid: azure-cognitiveservices-computervision.ImageDescription
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.TextOperationResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: TextOperationResult
    fullName: TextOperationResult
    uid: azure-cognitiveservices-computervision.TextOperationResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: TextOperationResult
    fullName: TextOperationResult
    uid: azure-cognitiveservices-computervision.TextOperationResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: TextOperationResult
    fullName: TextOperationResult
    uid: azure-cognitiveservices-computervision.TextOperationResult
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.ListModelsResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: ListModelsResult
    fullName: ListModelsResult
    uid: azure-cognitiveservices-computervision.ListModelsResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: ListModelsResult
    fullName: ListModelsResult
    uid: azure-cognitiveservices-computervision.ListModelsResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: ListModelsResult
    fullName: ListModelsResult
    uid: azure-cognitiveservices-computervision.ListModelsResult
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.OcrResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: OcrResult
    fullName: OcrResult
    uid: azure-cognitiveservices-computervision.OcrResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: OcrResult
    fullName: OcrResult
    uid: azure-cognitiveservices-computervision.OcrResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: OcrResult
    fullName: OcrResult
    uid: azure-cognitiveservices-computervision.OcrResult
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.TagResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: TagResult
    fullName: TagResult
    uid: azure-cognitiveservices-computervision.TagResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.TagResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: TagResult
    fullName: TagResult
    uid: azure-cognitiveservices-computervision.TagResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: TagResult
    fullName: TagResult
    uid: azure-cognitiveservices-computervision.TagResult
  - name: '>>'
    fullName: '>>'
