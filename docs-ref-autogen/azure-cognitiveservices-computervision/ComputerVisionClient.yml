### YamlMime:UniversalReference
ms.openlocfilehash: f7bb0a77329788feb31835819b61ccba9c59535e
ms.sourcegitcommit: efa2d98deffe8a0d41a8d63f9f07aa720862e6ab
ms.translationtype: MT
ms.contentlocale: it-IT
ms.lasthandoff: 12/13/2018
ms.locfileid: "52026127"
items:
- uid: azure-cognitiveservices-computervision.ComputerVisionClient
  name: ComputerVisionClient
  fullName: ComputerVisionClient
  children:
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.constructor
  - azure-cognitiveservices-computervision.ComputerVisionClient.credentials
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImage
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.endpoint
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult
  - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResultWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.listModels
  - azure-cognitiveservices-computervision.ComputerVisionClient.listModels_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.listModels_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.listModelsWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_2
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_1
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStreamWithHttpOperationResponse
  - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageWithHttpOperationResponse
  langs:
  - typeScript
  type: class
  summary: ''
  extends:
    name: ServiceClient
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage
  name: analyzeImage(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.  All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire.  Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta."
  syntax:
    content: 'function analyzeImage(url: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        Raggiungibile pubblicamente URL di un'immagine
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_2
  name: analyzeImage(string, Object, ServiceCallback<ImageAnalysis>)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.  All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire.  Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta."
  syntax:
    content: 'function analyzeImage(url: string, options: Object, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_1
  name: analyzeImage(string, ServiceCallback<ImageAnalysis>)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.  All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire.  Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta."
  syntax:
    content: 'function analyzeImage(url: string, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain
  name: analyzeImageByDomain(string, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomain(model: string, url: string, options?: Object)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Il contenuto specifico di dominio per riconoscere.
    - id: url
      type:
      - string
      description: >
        Raggiungibile pubblicamente URL di un'immagine
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_2
  name: analyzeImageByDomain(string, string, Object, ServiceCallback<DomainModelResults>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomain(model: string, url: string, options: Object, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_1
  name: analyzeImageByDomain(string, string, ServiceCallback<DomainModelResults>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomain(model: string, url: string, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream
  name: analyzeImageByDomainInStream(string, stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options?: Object)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Il contenuto specifico di dominio per riconoscere.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_2
  name: analyzeImageByDomainInStream(string, stream.Readable, Object, ServiceCallback<DomainModelResults>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options: Object, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_1
  name: analyzeImageByDomainInStream(string, stream.Readable, ServiceCallback<DomainModelResults>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, callback: ServiceCallback<DomainModelResults>)'
    parameters:
    - id: model
      type:
      - string
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.DomainModelResults>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStreamWithHttpOperationResponse
  name: analyzeImageByDomainInStreamWithHttpOperationResponse(string, stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomainInStreamWithHttpOperationResponse(model: string, image: stream.Readable, options?: Object)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Il contenuto specifico di dominio per riconoscere.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainWithHttpOperationResponse
  name: analyzeImageByDomainWithHttpOperationResponse(string, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio.  L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.  Attualmente, l'API fornisce solo un singolo modello specifico di dominio: celebrità. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.

    Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
  syntax:
    content: 'function analyzeImageByDomainWithHttpOperationResponse(model: string, url: string, options?: Object)'
    parameters:
    - id: model
      type:
      - string
      description: >
        Il contenuto specifico di dominio per riconoscere.
    - id: url
      type:
      - string
      description: >
        Raggiungibile pubblicamente URL di un'immagine
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream
  name: analyzeImageInStream(stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
  syntax:
    content: 'function analyzeImageInStream(image: stream.Readable, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_2
  name: analyzeImageInStream(stream.Readable, Object, ServiceCallback<ImageAnalysis>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
  syntax:
    content: 'function analyzeImageInStream(image: stream.Readable, options: Object, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_1
  name: analyzeImageInStream(stream.Readable, ServiceCallback<ImageAnalysis>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
  syntax:
    content: 'function analyzeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageAnalysis>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStreamWithHttpOperationResponse
  name: analyzeImageInStreamWithHttpOperationResponse(stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
  syntax:
    content: 'function analyzeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageWithHttpOperationResponse
  name: analyzeImageWithHttpOperationResponse(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.  All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire.  Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta."
  syntax:
    content: 'function analyzeImageWithHttpOperationResponse(url: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        Raggiungibile pubblicamente URL di un'immagine
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.constructor
  name: ComputerVisionClient(ServiceClientCredentials, string, ServiceClientOptions)
  children: []
  type: constructor
  langs:
  - typeScript
  summary: ''
  syntax:
    content: 'new ComputerVisionClient(credentials: ServiceClientCredentials, endpoint: string, options?: ServiceClientOptions)'
    parameters:
    - id: credentials
      type:
      - ServiceClientCredentials
      description: >
        Credenziali della sottoscrizione che lo identificano in modo univoco la sottoscrizione client.
    - id: endpoint
      type:
      - string
      description: >
        Endpoint di servizi cognitivi supportati
    - id: options
      type:
      - ServiceClientOptions
      description: ''
      optional: true
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.credentials
  name: credentials
  fullName: credentials
  children: []
  langs:
  - typeScript
  type: property
  summary: ''
  syntax:
    content: 'credentials: ServiceClientCredentials'
    return:
      type:
      - ServiceClientCredentials
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage
  name: describeImage(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImage(url: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        Raggiungibile pubblicamente URL di un'immagine
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_2
  name: describeImage(string, Object, ServiceCallback<ImageDescription>)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImage(url: string, options: Object, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_1
  name: describeImage(string, ServiceCallback<ImageDescription>)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImage(url: string, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream
  name: describeImageInStream(stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImageInStream(image: stream.Readable, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_2
  name: describeImageInStream(stream.Readable, Object, ServiceCallback<ImageDescription>)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImageInStream(image: stream.Readable, options: Object, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_1
  name: describeImageInStream(stream.Readable, ServiceCallback<ImageDescription>)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageDescription>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ImageDescription>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStreamWithHttpOperationResponse
  name: describeImageInStreamWithHttpOperationResponse(stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageWithHttpOperationResponse
  name: describeImageWithHttpOperationResponse(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete.  La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine.  Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese. Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function describeImageWithHttpOperationResponse(url: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        Raggiungibile pubblicamente URL di un'immagine
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.endpoint
  name: endpoint
  fullName: endpoint
  children: []
  langs:
  - typeScript
  type: property
  summary: ''
  syntax:
    content: 'endpoint: string'
    return:
      type:
      - string
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail
  name: generateThumbnail(number, number, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnail(width: number, height: number, url: string, options?: Object)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Larghezza dell'anteprima. Deve essere compreso tra 1 e 1024.

        Consigliati minimo pari a 50.
    - id: height
      type:
      - number
      description: >
        Altezza dell'anteprima. Deve essere compreso tra 1 e

        1024. Consigliati minimo pari a 50.
    - id: url
      type:
      - string
      description: >
        Raggiungibile pubblicamente URL di un'immagine
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_2
  name: generateThumbnail(number, number, string, Object, ServiceCallback<stream.Readable>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnail(width: number, height: number, url: string, options: Object, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_1
  name: generateThumbnail(number, number, string, ServiceCallback<stream.Readable>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnail(width: number, height: number, url: string, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream
  name: generateThumbnailInStream(number, number, stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options?: Object)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Larghezza dell'anteprima. Deve essere compreso tra 1 e 1024.

        Consigliati minimo pari a 50.
    - id: height
      type:
      - number
      description: >
        Altezza dell'anteprima. Deve essere compreso tra 1 e

        1024. Consigliati minimo pari a 50.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_2
  name: generateThumbnailInStream(number, number, stream.Readable, Object, ServiceCallback<stream.Readable>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options: Object, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_1
  name: generateThumbnailInStream(number, number, stream.Readable, ServiceCallback<stream.Readable>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, callback: ServiceCallback<stream.Readable>)'
    parameters:
    - id: width
      type:
      - number
      description: ''
    - id: height
      type:
      - number
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<stream.Readable>
      description: ''
    return:
      type:
      - Promise<stream.Readable>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStreamWithHttpOperationResponse
  name: generateThumbnailInStreamWithHttpOperationResponse(number, number, stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnailInStreamWithHttpOperationResponse(width: number, height: number, image: stream.Readable, options?: Object)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Larghezza dell'anteprima. Deve essere compreso tra 1 e 1024.

        Consigliati minimo pari a 50.
    - id: height
      type:
      - number
      description: >
        Altezza dell'anteprima. Deve essere compreso tra 1 e

        1024. Consigliati minimo pari a 50.
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<stream.Readable>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailWithHttpOperationResponse
  name: generateThumbnailWithHttpOperationResponse(number, number, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.

    Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input. Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
  syntax:
    content: 'function generateThumbnailWithHttpOperationResponse(width: number, height: number, url: string, options?: Object)'
    parameters:
    - id: width
      type:
      - number
      description: >
        Larghezza dell'anteprima. Deve essere compreso tra 1 e 1024.

        Consigliati minimo pari a 50.
    - id: height
      type:
      - number
      description: >
        Altezza dell'anteprima. Deve essere compreso tra 1 e

        1024. Consigliati minimo pari a 50.
    - id: url
      type:
      - string
      description: >
        Raggiungibile pubblicamente URL di un'immagine
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<stream.Readable>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult
  name: getTextOperationResult(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa interfaccia viene utilizzata per ottenere il risultato dell'operazione di testo. L'URL per questa interfaccia deve essere recuperato dal campo 'Operation-Location' restituito dall'interfaccia di riconoscere il testo.
  syntax:
    content: 'function getTextOperationResult(operationId: string, options?: Object)'
    parameters:
    - id: operationId
      type:
      - string
      description: >
        ID dell'operazione di testo restituito nella risposta del 'Riconosce testo'
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TextOperationResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_2
  name: getTextOperationResult(string, Object, ServiceCallback<TextOperationResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa interfaccia viene utilizzata per ottenere il risultato dell'operazione di testo. L'URL per questa interfaccia deve essere recuperato dal campo 'Operation-Location' restituito dall'interfaccia di riconoscere il testo.
  syntax:
    content: 'function getTextOperationResult(operationId: string, options: Object, callback: ServiceCallback<TextOperationResult>)'
    parameters:
    - id: operationId
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TextOperationResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_1
  name: getTextOperationResult(string, ServiceCallback<TextOperationResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa interfaccia viene utilizzata per ottenere il risultato dell'operazione di testo. L'URL per questa interfaccia deve essere recuperato dal campo 'Operation-Location' restituito dall'interfaccia di riconoscere il testo.
  syntax:
    content: 'function getTextOperationResult(operationId: string, callback: ServiceCallback<TextOperationResult>)'
    parameters:
    - id: operationId
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TextOperationResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResultWithHttpOperationResponse
  name: getTextOperationResultWithHttpOperationResponse(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa interfaccia viene utilizzata per ottenere il risultato dell'operazione di testo. L'URL per questa interfaccia deve essere recuperato dal campo 'Operation-Location' restituito dall'interfaccia di riconoscere il testo.
  syntax:
    content: 'function getTextOperationResultWithHttpOperationResponse(operationId: string, options?: Object)'
    parameters:
    - id: operationId
      type:
      - string
      description: >
        ID dell'operazione di testo restituito nella risposta del 'Riconosce testo'
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels
  name: listModels(Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione restituisce l'elenco di modelli specifici di dominio che sono supportati per l'API visione artificiale.  L'API supporta attualmente solo un modello specifico di dominio: un sistema di riconoscimento di celebrità. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function listModels(options?: Object)'
    parameters:
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ListModelsResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels_2
  name: listModels(Object, ServiceCallback<ListModelsResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione restituisce l'elenco di modelli specifici di dominio che sono supportati per l'API visione artificiale.  L'API supporta attualmente solo un modello specifico di dominio: un sistema di riconoscimento di celebrità. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function listModels(options: Object, callback: ServiceCallback<ListModelsResult>)'
    parameters:
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ListModelsResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels_1
  name: listModels(ServiceCallback<ListModelsResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione restituisce l'elenco di modelli specifici di dominio che sono supportati per l'API visione artificiale.  L'API supporta attualmente solo un modello specifico di dominio: un sistema di riconoscimento di celebrità. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function listModels(callback: ServiceCallback<ListModelsResult>)'
    parameters:
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.ListModelsResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModelsWithHttpOperationResponse
  name: listModelsWithHttpOperationResponse(Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: "Questa operazione restituisce l'elenco di modelli specifici di dominio che sono supportati per l'API visione artificiale.  L'API supporta attualmente solo un modello specifico di dominio: un sistema di riconoscimento di celebrità. Una risposta con esito positivo verrà restituita in formato JSON.  Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore."
  syntax:
    content: 'function listModelsWithHttpOperationResponse(options?: Object)'
    parameters:
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText
  name: recognizePrintedText(boolean, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options?: Object)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Possibilità di rilevare l'orientamento del testo nell'immagine. Con detectOrientation = true di OCR servizio prova a rilevare l'orientamento dell'immagine e correggere l'errore prima dell'ulteriore elaborazione (ad esempio, se è capovolto).
    - id: url
      type:
      - string
      description: >
        Raggiungibile pubblicamente URL di un'immagine
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_2
  name: recognizePrintedText(boolean, string, Object, ServiceCallback<OcrResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options: Object, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_1
  name: recognizePrintedText(boolean, string, ServiceCallback<OcrResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedText(detectOrientation: boolean, url: string, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream
  name: recognizePrintedTextInStream(boolean, stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options?: Object)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Possibilità di rilevare l'orientamento del testo nell'immagine. Con detectOrientation = true di OCR servizio prova a rilevare l'orientamento dell'immagine e correggere l'errore prima dell'ulteriore elaborazione (ad esempio, se è capovolto).
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_2
  name: recognizePrintedTextInStream(boolean, stream.Readable, Object, ServiceCallback<OcrResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options: Object, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_1
  name: recognizePrintedTextInStream(boolean, stream.Readable, ServiceCallback<OcrResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, callback: ServiceCallback<OcrResult>)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: ''
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.OcrResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStreamWithHttpOperationResponse
  name: recognizePrintedTextInStreamWithHttpOperationResponse(boolean, stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedTextInStreamWithHttpOperationResponse(detectOrientation: boolean, image: stream.Readable, options?: Object)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Possibilità di rilevare l'orientamento del testo nell'immagine. Con detectOrientation = true di OCR servizio prova a rilevare l'orientamento dell'immagine e correggere l'errore prima dell'ulteriore elaborazione (ad esempio, se è capovolto).
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextWithHttpOperationResponse
  name: recognizePrintedTextWithHttpOperationResponse(boolean, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: >-
    Riconoscimento ottico dei caratteri (OCR) rileva il testo stampato in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.

    Al termine dell'operazione, verranno restituiti i risultati di OCR. In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
  syntax:
    content: 'function recognizePrintedTextWithHttpOperationResponse(detectOrientation: boolean, url: string, options?: Object)'
    parameters:
    - id: detectOrientation
      type:
      - boolean
      description: >
        Possibilità di rilevare l'orientamento del testo nell'immagine. Con detectOrientation = true di OCR servizio prova a rilevare l'orientamento dell'immagine e correggere l'errore prima dell'ulteriore elaborazione (ad esempio, se è capovolto).
    - id: url
      type:
      - string
      description: >
        Raggiungibile pubblicamente URL di un'immagine
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText
  name: recognizeText(string, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato 'Operation-Location'. Il campo 'Operation-Location' contiene l'URL che è necessario usare per l'operazione Ottieni riconoscere testo il risultato dell'operazione.
  syntax:
    content: 'function recognizeText(url: string, mode: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        Raggiungibile pubblicamente URL di un'immagine
    - id: mode
      type:
      - string
      description: >
        Tipo di testo da riconoscere. Possibili valori: 'Scritto dall'utente', 'stampato'
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_2
  name: recognizeText(string, string, Object, ServiceCallback<void>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato 'Operation-Location'. Il campo 'Operation-Location' contiene l'URL che è necessario usare per l'operazione Ottieni riconoscere testo il risultato dell'operazione.
  syntax:
    content: 'function recognizeText(url: string, mode: string, options: Object, callback: ServiceCallback<void>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: mode
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_1
  name: recognizeText(string, string, ServiceCallback<void>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato 'Operation-Location'. Il campo 'Operation-Location' contiene l'URL che è necessario usare per l'operazione Ottieni riconoscere testo il risultato dell'operazione.
  syntax:
    content: 'function recognizeText(url: string, mode: string, callback: ServiceCallback<void>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: mode
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream
  name: recognizeTextInStream(stream.Readable, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato 'Operation-Location'. Il campo 'Operation-Location' contiene l'URL che è necessario usare per l'operazione Ottieni riconoscere testo il risultato dell'operazione.
  syntax:
    content: 'function recognizeTextInStream(image: stream.Readable, mode: string, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: mode
      type:
      - string
      description: >
        Tipo di testo da riconoscere. Possibili valori: 'Scritto dall'utente', 'stampato'
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_2
  name: recognizeTextInStream(stream.Readable, string, Object, ServiceCallback<void>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato 'Operation-Location'. Il campo 'Operation-Location' contiene l'URL che è necessario usare per l'operazione Ottieni riconoscere testo il risultato dell'operazione.
  syntax:
    content: 'function recognizeTextInStream(image: stream.Readable, mode: string, options: Object, callback: ServiceCallback<void>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: mode
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_1
  name: recognizeTextInStream(stream.Readable, string, ServiceCallback<void>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato 'Operation-Location'. Il campo 'Operation-Location' contiene l'URL che è necessario usare per l'operazione Ottieni riconoscere testo il risultato dell'operazione.
  syntax:
    content: 'function recognizeTextInStream(image: stream.Readable, mode: string, callback: ServiceCallback<void>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: mode
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<void>
      description: ''
    return:
      type:
      - Promise<void>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStreamWithHttpOperationResponse
  name: recognizeTextInStreamWithHttpOperationResponse(stream.Readable, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato 'Operation-Location'. Il campo 'Operation-Location' contiene l'URL che è necessario usare per l'operazione Ottieni riconoscere testo il risultato dell'operazione.
  syntax:
    content: 'function recognizeTextInStreamWithHttpOperationResponse(image: stream.Readable, mode: string, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: mode
      type:
      - string
      description: >
        Tipo di testo da riconoscere. Possibili valori: 'Scritto dall'utente', 'stampato'
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<void>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextWithHttpOperationResponse
  name: recognizeTextWithHttpOperationResponse(string, string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Riconoscere l'operazione del testo. Quando si usa l'interfaccia di riconoscere il testo, la risposta contiene un campo denominato 'Operation-Location'. Il campo 'Operation-Location' contiene l'URL che è necessario usare per l'operazione Ottieni riconoscere testo il risultato dell'operazione.
  syntax:
    content: 'function recognizeTextWithHttpOperationResponse(url: string, mode: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        Raggiungibile pubblicamente URL di un'immagine
    - id: mode
      type:
      - string
      description: >
        Tipo di testo da riconoscere. Possibili valori: 'Scritto dall'utente', 'stampato'
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<void>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage
  name: tagImage(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello' tag' può essere accompagnata dall'hint 'strumento musicale'. Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImage(url: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        Raggiungibile pubblicamente URL di un'immagine
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_2
  name: tagImage(string, Object, ServiceCallback<TagResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello' tag' può essere accompagnata dall'hint 'strumento musicale'. Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImage(url: string, options: Object, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_1
  name: tagImage(string, ServiceCallback<TagResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello' tag' può essere accompagnata dall'hint 'strumento musicale'. Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImage(url: string, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: url
      type:
      - string
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream
  name: tagImageInStream(stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello' tag' può essere accompagnata dall'hint 'strumento musicale'. Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImageInStream(image: stream.Readable, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_2
  name: tagImageInStream(stream.Readable, Object, ServiceCallback<TagResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello' tag' può essere accompagnata dall'hint 'strumento musicale'. Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImageInStream(image: stream.Readable, options: Object, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: options
      type:
      - Object
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_1
  name: tagImageInStream(stream.Readable, ServiceCallback<TagResult>)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello' tag' può essere accompagnata dall'hint 'strumento musicale'. Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImageInStream(image: stream.Readable, callback: ServiceCallback<TagResult>)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: ''
    - id: callback
      type:
      - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
      description: ''
    return:
      type:
      - Promise<azure-cognitiveservices-computervision.TagResult>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStreamWithHttpOperationResponse
  name: tagImageInStreamWithHttpOperationResponse(stream.Readable, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello' tag' può essere accompagnata dall'hint 'strumento musicale'. Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
    parameters:
    - id: image
      type:
      - stream.Readable
      description: >
        Un flusso dell'immagine.
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
  package: azure-cognitiveservices-computervision
- uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageWithHttpOperationResponse
  name: tagImageWithHttpOperationResponse(string, Object)
  children: []
  type: method
  langs:
  - typeScript
  summary: Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello' tag' può essere accompagnata dall'hint 'strumento musicale'. Tutti i tag sono in inglese.
  syntax:
    content: 'function tagImageWithHttpOperationResponse(url: string, options?: Object)'
    parameters:
    - id: url
      type:
      - string
      description: >
        Raggiungibile pubblicamente URL di un'immagine
    - id: options
      type:
      - Object
      description: ''
      optional: true
    return:
      type:
      - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
  package: azure-cognitiveservices-computervision
references:
- uid: Promise<azure-cognitiveservices-computervision.ImageAnalysis>
  name: ImageAnalysis>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: ImageAnalysis
    fullName: ImageAnalysis
    uid: azure-cognitiveservices-computervision.ImageAnalysis
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
  name: ImageAnalysis>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: ImageAnalysis
    fullName: ImageAnalysis
    uid: azure-cognitiveservices-computervision.ImageAnalysis
  - name: '>'
    fullName: '>'
- uid: Promise<azure-cognitiveservices-computervision.DomainModelResults>
  name: DomainModelResults>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: DomainModelResults
    fullName: DomainModelResults
    uid: azure-cognitiveservices-computervision.DomainModelResults
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
  name: DomainModelResults>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: DomainModelResults
    fullName: DomainModelResults
    uid: azure-cognitiveservices-computervision.DomainModelResults
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
  name: DomainModelResults>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: DomainModelResults
    fullName: DomainModelResults
    uid: azure-cognitiveservices-computervision.DomainModelResults
  - name: '>>'
    fullName: '>>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
  name: ImageAnalysis>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: ImageAnalysis
    fullName: ImageAnalysis
    uid: azure-cognitiveservices-computervision.ImageAnalysis
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.ImageDescription>
  name: ImageDescription>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: ImageDescription
    fullName: ImageDescription
    uid: azure-cognitiveservices-computervision.ImageDescription
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
  name: ImageDescription>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: ImageDescription
    fullName: ImageDescription
    uid: azure-cognitiveservices-computervision.ImageDescription
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
  name: ImageDescription>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: ImageDescription
    fullName: ImageDescription
    uid: azure-cognitiveservices-computervision.ImageDescription
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.TextOperationResult>
  name: TextOperationResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: TextOperationResult
    fullName: TextOperationResult
    uid: azure-cognitiveservices-computervision.TextOperationResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
  name: TextOperationResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: TextOperationResult
    fullName: TextOperationResult
    uid: azure-cognitiveservices-computervision.TextOperationResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
  name: TextOperationResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: TextOperationResult
    fullName: TextOperationResult
    uid: azure-cognitiveservices-computervision.TextOperationResult
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.ListModelsResult>
  name: ListModelsResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: ListModelsResult
    fullName: ListModelsResult
    uid: azure-cognitiveservices-computervision.ListModelsResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
  name: ListModelsResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: ListModelsResult
    fullName: ListModelsResult
    uid: azure-cognitiveservices-computervision.ListModelsResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
  name: ListModelsResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: ListModelsResult
    fullName: ListModelsResult
    uid: azure-cognitiveservices-computervision.ListModelsResult
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.OcrResult>
  name: OcrResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: OcrResult
    fullName: OcrResult
    uid: azure-cognitiveservices-computervision.OcrResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
  name: OcrResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: OcrResult
    fullName: OcrResult
    uid: azure-cognitiveservices-computervision.OcrResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
  name: OcrResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: OcrResult
    fullName: OcrResult
    uid: azure-cognitiveservices-computervision.OcrResult
  - name: '>>'
    fullName: '>>'
- uid: Promise<azure-cognitiveservices-computervision.TagResult>
  name: TagResult>
  spec.typeScript:
  - name: Promise<
    fullName: Promise<
  - name: TagResult
    fullName: TagResult
    uid: azure-cognitiveservices-computervision.TagResult
  - name: '>'
    fullName: '>'
- uid: ServiceCallback<azure-cognitiveservices-computervision.TagResult>
  name: TagResult>
  spec.typeScript:
  - name: ServiceCallback<
    fullName: ServiceCallback<
  - name: TagResult
    fullName: TagResult
    uid: azure-cognitiveservices-computervision.TagResult
  - name: '>'
    fullName: '>'
- uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
  name: TagResult>>
  spec.typeScript:
  - name: Promise<HttpOperationResponse<
    fullName: Promise<HttpOperationResponse<
  - name: TagResult
    fullName: TagResult
    uid: azure-cognitiveservices-computervision.TagResult
  - name: '>>'
    fullName: '>>'
