### YamlMime:UniversalReference
items:
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient
    name: ComputerVisionClient
    fullName: ComputerVisionClient
    children:
      - azure-cognitiveservices-computervision.ComputerVisionClient.addUserAgentInfo
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.constructor
      - azure-cognitiveservices-computervision.ComputerVisionClient.credentials
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImage
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.describeImageWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.endpoint
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.getPackageJsonInfo
      - azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult
      - azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResultWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult
      - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResultWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModels
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModels_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModels_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.listModelsWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.sendRequest_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.sendRequest
      - azure-cognitiveservices-computervision.ComputerVisionClient.sendRequestWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_2
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_1
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStreamWithHttpOperationResponse
      - azure-cognitiveservices-computervision.ComputerVisionClient.tagImageWithHttpOperationResponse
    langs:
      - typeScript
    type: class
    summary: ''
    extends:
      name: ServiceClient
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.addUserAgentInfo
    name: addUserAgentInfo(any)
    children: []
    type: method
    langs:
      - typeScript
    summary: Consente di aggiungere informazioni personalizzate a intestazione agente utente
    syntax:
      content: 'function addUserAgentInfo(additionalUserAgentInfo: any)'
      parameters:
        - id: additionalUserAgentInfo
          type:
            - any
          description: |
            informazioni da aggiungere all'intestazione agente utente, sotto forma di stringa.
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage
    name: 'analyzeImage(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire. Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImage(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_2
    name: 'analyzeImage(string, Object, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire. Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImage(url: string, options: Object, callback: ServiceCallback<ImageAnalysis>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImage_1
    name: 'analyzeImage(string, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire. Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImage(url: string, callback: ServiceCallback<ImageAnalysis>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain
    name: 'analyzeImageByDomain(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio. L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.
      Attualmente, l'API fornisce i modelli specifici di dominio: celebrità, punti di riferimento.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON.
      Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImageByDomain(model: string, url: string, options?: Object)'
      parameters:
        - id: model
          type:
            - string
          description: |
            Il contenuto specifico di dominio per riconoscere.
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_2
    name: 'analyzeImageByDomain(string, string, Object, ServiceCallback<DomainModelResults>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio. L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.
      Attualmente, l'API fornisce i modelli specifici di dominio: celebrità, punti di riferimento.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON.
      Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImageByDomain(model: string, url: string, options: Object, callback: ServiceCallback<DomainModelResults>)'
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomain_1
    name: 'analyzeImageByDomain(string, string, ServiceCallback<DomainModelResults>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio. L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.
      Attualmente, l'API fornisce i modelli specifici di dominio: celebrità, punti di riferimento.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON.
      Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImageByDomain(model: string, url: string, callback: ServiceCallback<DomainModelResults>)'
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream
    name: 'analyzeImageByDomainInStream(string, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio. L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.
      Attualmente, l'API fornisce i modelli specifici di dominio: celebrità, punti di riferimento.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON.
      Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options?: Object)'
      parameters:
        - id: model
          type:
            - string
          description: |
            Il contenuto specifico di dominio per riconoscere.
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_2
    name: 'analyzeImageByDomainInStream(string, stream.Readable, Object, ServiceCallback<DomainModelResults>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio. L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.
      Attualmente, l'API fornisce i modelli specifici di dominio: celebrità, punti di riferimento.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON.
      Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, options: Object, callback: ServiceCallback<DomainModelResults>)'
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStream_1
    name: 'analyzeImageByDomainInStream(string, stream.Readable, ServiceCallback<DomainModelResults>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio. L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.
      Attualmente, l'API fornisce i modelli specifici di dominio: celebrità, punti di riferimento.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON.
      Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImageByDomainInStream(model: string, image: stream.Readable, callback: ServiceCallback<DomainModelResults>)'
      parameters:
        - id: model
          type:
            - string
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DomainModelResults>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainInStreamWithHttpOperationResponse
    name: 'analyzeImageByDomainInStreamWithHttpOperationResponse(string, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio. L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.
      Attualmente, l'API fornisce i modelli specifici di dominio: celebrità, punti di riferimento.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON.
      Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImageByDomainInStreamWithHttpOperationResponse(model: string, image: stream.Readable, options?: Object)'
      parameters:
        - id: model
          type:
            - string
          description: |
            Il contenuto specifico di dominio per riconoscere.
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageByDomainWithHttpOperationResponse
    name: 'analyzeImageByDomainWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione riconosce il contenuto all'interno di un'immagine tramite l'applicazione di un modello specifico di dominio. L'elenco dei modelli specifici di dominio che sono supportati per l'API visione artificiale può essere recuperato tramite la richiesta di recupero /models.
      Attualmente, l'API fornisce i modelli specifici di dominio: celebrità, punti di riferimento.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON.
      Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImageByDomainWithHttpOperationResponse(model: string, url: string, options?: Object)'
      parameters:
        - id: model
          type:
            - string
          description: |
            Il contenuto specifico di dominio per riconoscere.
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream
    name: 'analyzeImageInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire. Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImageInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_2
    name: 'analyzeImageInStream(stream.Readable, Object, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire. Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImageInStream(image: stream.Readable, options: Object, callback: ServiceCallback<ImageAnalysis>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStream_1
    name: 'analyzeImageInStream(stream.Readable, ServiceCallback<ImageAnalysis>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire. Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageAnalysis>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageInStreamWithHttpOperationResponse
    name: 'analyzeImageInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire. Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.analyzeImageWithHttpOperationResponse
    name: 'analyzeImageWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione estrae un set completo di caratteristiche visive sulla base del contenuto di immagine.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine. All'interno della richiesta, è presente un parametro facoltativo che consente di scegliere le funzionalità da restituire. Per impostazione predefinita, le categorie di immagine vengono restituite nella risposta.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function analyzeImageWithHttpOperationResponse(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile
    name: 'batchReadFile(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Utilizzare questa interfaccia per ottenere il risultato di un''operazione di lettura, che utilizza gli algoritmi di riconoscimento ottico dei caratteri (OCR) d''avanguardia ottimizzati per i documenti di grandi quantità di testo. Quando si usa l''interfaccia di leggere il File, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l''URL che è necessario usare per l''operazione di "Risultato dell''operazione in lettura" per accedere ai OCR risultati.'
    syntax:
      content: 'function batchReadFile(url: string, mode: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: mode
          type:
            - string
          description: |
            Tipo di testo da riconoscere. I valori possibili sono: 'Scritto dall'utente', 'stampato'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_2
    name: 'batchReadFile(string, string, Object, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Utilizzare questa interfaccia per ottenere il risultato di un''operazione di lettura, che utilizza gli algoritmi di riconoscimento ottico dei caratteri (OCR) d''avanguardia ottimizzati per i documenti di grandi quantità di testo. Quando si usa l''interfaccia di leggere il File, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l''URL che è necessario usare per l''operazione di "Risultato dell''operazione in lettura" per accedere ai OCR risultati.'
    syntax:
      content: 'function batchReadFile(url: string, mode: string, options: Object, callback: ServiceCallback<void>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFile_1
    name: 'batchReadFile(string, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Utilizzare questa interfaccia per ottenere il risultato di un''operazione di lettura, che utilizza gli algoritmi di riconoscimento ottico dei caratteri (OCR) d''avanguardia ottimizzati per i documenti di grandi quantità di testo. Quando si usa l''interfaccia di leggere il File, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l''URL che è necessario usare per l''operazione di "Risultato dell''operazione in lettura" per accedere ai OCR risultati.'
    syntax:
      content: 'function batchReadFile(url: string, mode: string, callback: ServiceCallback<void>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream
    name: 'batchReadFileInStream(stream.Readable, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Utilizzare questa interfaccia per ottenere il risultato di un''operazione di lettura documento che utilizza gli algoritmi di riconoscimento ottico dei caratteri (OCR) d''avanguardia ottimizzati per i documenti di grandi quantità di testo. Quando si usa l''interfaccia a documenti di lettura, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l''URL che è necessario usare per la "lettura risultato operazione di acquisizione" per accedere ai OCR risultati.'
    syntax:
      content: 'function batchReadFileInStream(image: stream.Readable, mode: string, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: mode
          type:
            - string
          description: |
            Tipo di testo da riconoscere. I valori possibili sono: 'Scritto dall'utente', 'stampato'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_2
    name: 'batchReadFileInStream(stream.Readable, string, Object, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Utilizzare questa interfaccia per ottenere il risultato di un''operazione di lettura documento che utilizza gli algoritmi di riconoscimento ottico dei caratteri (OCR) d''avanguardia ottimizzati per i documenti di grandi quantità di testo. Quando si usa l''interfaccia a documenti di lettura, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l''URL che è necessario usare per la "lettura risultato operazione di acquisizione" per accedere ai OCR risultati.'
    syntax:
      content: 'function batchReadFileInStream(image: stream.Readable, mode: string, options: Object, callback: ServiceCallback<void>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStream_1
    name: 'batchReadFileInStream(stream.Readable, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Utilizzare questa interfaccia per ottenere il risultato di un''operazione di lettura documento che utilizza gli algoritmi di riconoscimento ottico dei caratteri (OCR) d''avanguardia ottimizzati per i documenti di grandi quantità di testo. Quando si usa l''interfaccia a documenti di lettura, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l''URL che è necessario usare per la "lettura risultato operazione di acquisizione" per accedere ai OCR risultati.'
    syntax:
      content: 'function batchReadFileInStream(image: stream.Readable, mode: string, callback: ServiceCallback<void>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileInStreamWithHttpOperationResponse
    name: 'batchReadFileInStreamWithHttpOperationResponse(stream.Readable, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Utilizzare questa interfaccia per ottenere il risultato di un''operazione di lettura documento che utilizza gli algoritmi di riconoscimento ottico dei caratteri (OCR) d''avanguardia ottimizzati per i documenti di grandi quantità di testo. Quando si usa l''interfaccia a documenti di lettura, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l''URL che è necessario usare per la "lettura risultato operazione di acquisizione" per accedere ai OCR risultati.'
    syntax:
      content: 'function batchReadFileInStreamWithHttpOperationResponse(image: stream.Readable, mode: string, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: mode
          type:
            - string
          description: |
            Tipo di testo da riconoscere. I valori possibili sono: 'Scritto dall'utente', 'stampato'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.batchReadFileWithHttpOperationResponse
    name: 'batchReadFileWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Utilizzare questa interfaccia per ottenere il risultato di un''operazione di lettura, che utilizza gli algoritmi di riconoscimento ottico dei caratteri (OCR) d''avanguardia ottimizzati per i documenti di grandi quantità di testo. Quando si usa l''interfaccia di leggere il File, la risposta contiene un campo denominato "Operation-Location". Il campo "Operation-Location" contiene l''URL che è necessario usare per l''operazione di "Risultato dell''operazione in lettura" per accedere ai OCR risultati.'
    syntax:
      content: 'function batchReadFileWithHttpOperationResponse(url: string, mode: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: mode
          type:
            - string
          description: |
            Tipo di testo da riconoscere. I valori possibili sono: 'Scritto dall'utente', 'stampato'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.constructor
    name: 'ComputerVisionClient(ServiceClientCredentials, string, ServiceClientOptions)'
    children: []
    type: constructor
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'new ComputerVisionClient(credentials: ServiceClientCredentials, endpoint: string, options?: ServiceClientOptions)'
      parameters:
        - id: credentials
          type:
            - ServiceClientCredentials
          description: |
            Credenziali della sottoscrizione che lo identificano in modo univoco la sottoscrizione client.
        - id: endpoint
          type:
            - string
          description: |
            Endpoint di servizi cognitivi supportati.
        - id: options
          type:
            - ServiceClientOptions
          description: ''
          optional: true
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.credentials
    name: credentials
    fullName: credentials
    children: []
    langs:
      - typeScript
    type: property
    summary: ''
    syntax:
      content: 'credentials: ServiceClientCredentials'
      return:
        type:
          - ServiceClientCredentials
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage
    name: 'describeImage(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete. La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine. Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function describeImage(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_2
    name: 'describeImage(string, Object, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete. La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine. Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function describeImage(url: string, options: Object, callback: ServiceCallback<ImageDescription>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImage_1
    name: 'describeImage(string, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete. La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine. Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function describeImage(url: string, callback: ServiceCallback<ImageDescription>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream
    name: 'describeImageInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete. La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine. Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function describeImageInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_2
    name: 'describeImageInStream(stream.Readable, Object, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete. La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine. Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function describeImageInStream(image: stream.Readable, options: Object, callback: ServiceCallback<ImageDescription>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStream_1
    name: 'describeImageInStream(stream.Readable, ServiceCallback<ImageDescription>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete. La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine. Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function describeImageInStream(image: stream.Readable, callback: ServiceCallback<ImageDescription>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ImageDescription>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageInStreamWithHttpOperationResponse
    name: 'describeImageInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete. La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine. Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function describeImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.describeImageWithHttpOperationResponse
    name: 'describeImageWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera una descrizione di un'immagine nella lingua leggibile con frasi complete. La descrizione si basa su una raccolta di tag del contenuto, ovvero vengono restituiti anche dall'operazione. Può essere generata più di una descrizione per ogni immagine. Le descrizioni sono ordinate per relativo punteggio di confidenza. Tutte le descrizioni sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function describeImageWithHttpOperationResponse(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects
    name: 'detectObjects(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Esegue il rilevamento di oggetti sull'immagine specificata.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function detectObjects(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_2
    name: 'detectObjects(string, Object, ServiceCallback<DetectResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Esegue il rilevamento di oggetti sull'immagine specificata.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function detectObjects(url: string, options: Object, callback: ServiceCallback<DetectResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjects_1
    name: 'detectObjects(string, ServiceCallback<DetectResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Esegue il rilevamento di oggetti sull'immagine specificata.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function detectObjects(url: string, callback: ServiceCallback<DetectResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream
    name: 'detectObjectsInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Esegue il rilevamento di oggetti sull'immagine specificata.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function detectObjectsInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_2
    name: 'detectObjectsInStream(stream.Readable, Object, ServiceCallback<DetectResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Esegue il rilevamento di oggetti sull'immagine specificata.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function detectObjectsInStream(image: stream.Readable, options: Object, callback: ServiceCallback<DetectResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStream_1
    name: 'detectObjectsInStream(stream.Readable, ServiceCallback<DetectResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Esegue il rilevamento di oggetti sull'immagine specificata.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function detectObjectsInStream(image: stream.Readable, callback: ServiceCallback<DetectResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.DetectResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsInStreamWithHttpOperationResponse
    name: 'detectObjectsInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Esegue il rilevamento di oggetti sull'immagine specificata.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function detectObjectsInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DetectResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.detectObjectsWithHttpOperationResponse
    name: 'detectObjectsWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Esegue il rilevamento di oggetti sull'immagine specificata.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function detectObjectsWithHttpOperationResponse(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DetectResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.endpoint
    name: endpoint
    fullName: endpoint
    children: []
    langs:
      - typeScript
    type: property
    summary: ''
    syntax:
      content: 'endpoint: string'
      return:
        type:
          - string
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail
    name: 'generateThumbnail(number, number, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.
      Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input.
      Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function generateThumbnail(width: number, height: number, url: string, options?: Object)'
      parameters:
        - id: width
          type:
            - number
          description: |
            Larghezza dell'anteprima, in pixel. Deve essere compreso tra 1 e 1024. Consigliati minimo pari a 50.
        - id: height
          type:
            - number
          description: |
            Altezza dell'anteprima, in pixel. Deve essere compreso tra 1 e 1024. Consigliati minimo pari a 50.
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_2
    name: 'generateThumbnail(number, number, string, Object, ServiceCallback<stream.Readable>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.
      Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input.
      Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function generateThumbnail(width: number, height: number, url: string, options: Object, callback: ServiceCallback<stream.Readable>)'
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnail_1
    name: 'generateThumbnail(number, number, string, ServiceCallback<stream.Readable>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.
      Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input.
      Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function generateThumbnail(width: number, height: number, url: string, callback: ServiceCallback<stream.Readable>)'
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream
    name: 'generateThumbnailInStream(number, number, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.
      Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input.
      Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options?: Object)'
      parameters:
        - id: width
          type:
            - number
          description: |
            Larghezza dell'anteprima, in pixel. Deve essere compreso tra 1 e 1024. Consigliati minimo pari a 50.
        - id: height
          type:
            - number
          description: |
            Altezza dell'anteprima, in pixel. Deve essere compreso tra 1 e 1024. Consigliati minimo pari a 50.
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_2
    name: 'generateThumbnailInStream(number, number, stream.Readable, Object, ServiceCallback<stream.Readable>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.
      Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input.
      Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, options: Object, callback: ServiceCallback<stream.Readable>)'
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStream_1
    name: 'generateThumbnailInStream(number, number, stream.Readable, ServiceCallback<stream.Readable>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.
      Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input.
      Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function generateThumbnailInStream(width: number, height: number, image: stream.Readable, callback: ServiceCallback<stream.Readable>)'
      parameters:
        - id: width
          type:
            - number
          description: ''
        - id: height
          type:
            - number
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<stream.Readable>
          description: ''
      return:
        type:
          - Promise<stream.Readable>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailInStreamWithHttpOperationResponse
    name: 'generateThumbnailInStreamWithHttpOperationResponse(number, number, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.
      Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input.
      Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function generateThumbnailInStreamWithHttpOperationResponse(width: number, height: number, image: stream.Readable, options?: Object)'
      parameters:
        - id: width
          type:
            - number
          description: |
            Larghezza dell'anteprima, in pixel. Deve essere compreso tra 1 e 1024. Consigliati minimo pari a 50.
        - id: height
          type:
            - number
          description: |
            Altezza dell'anteprima, in pixel. Deve essere compreso tra 1 e 1024. Consigliati minimo pari a 50.
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<stream.Readable>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.generateThumbnailWithHttpOperationResponse
    name: 'generateThumbnailWithHttpOperationResponse(number, number, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un'immagine di anteprima con la larghezza specificata dall'utente e l'altezza. Per impostazione predefinita, il servizio analizza l'immagine, identifica l'area di interesse (ROI) e genera le coordinate di ritaglio intelligente basate il rendimento del capitale investito.
      Ritaglio intelligente è utile quando si specifica un rapporto di aspetto che è diverso da quello dell'immagine di input.
      Una risposta con esito positivo contiene il file binario dell'immagine di anteprima. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, InvalidThumbnailSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function generateThumbnailWithHttpOperationResponse(width: number, height: number, url: string, options?: Object)'
      parameters:
        - id: width
          type:
            - number
          description: |
            Larghezza dell'anteprima, in pixel. Deve essere compreso tra 1 e 1024. Consigliati minimo pari a 50.
        - id: height
          type:
            - number
          description: |
            Altezza dell'anteprima, in pixel. Deve essere compreso tra 1 e 1024. Consigliati minimo pari a 50.
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<stream.Readable>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest
    name: 'getAreaOfInterest(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione restituisce un rettangolo attorno all'area più importante dell'immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function getAreaOfInterest(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_2
    name: 'getAreaOfInterest(string, Object, ServiceCallback<AreaOfInterestResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione restituisce un rettangolo attorno all'area più importante dell'immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function getAreaOfInterest(url: string, options: Object, callback: ServiceCallback<AreaOfInterestResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterest_1
    name: 'getAreaOfInterest(string, ServiceCallback<AreaOfInterestResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione restituisce un rettangolo attorno all'area più importante dell'immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function getAreaOfInterest(url: string, callback: ServiceCallback<AreaOfInterestResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream
    name: 'getAreaOfInterestInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione restituisce un rettangolo attorno all'area più importante dell'immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function getAreaOfInterestInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_2
    name: 'getAreaOfInterestInStream(stream.Readable, Object, ServiceCallback<AreaOfInterestResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione restituisce un rettangolo attorno all'area più importante dell'immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function getAreaOfInterestInStream(image: stream.Readable, options: Object, callback: ServiceCallback<AreaOfInterestResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStream_1
    name: 'getAreaOfInterestInStream(stream.Readable, ServiceCallback<AreaOfInterestResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione restituisce un rettangolo attorno all'area più importante dell'immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function getAreaOfInterestInStream(image: stream.Readable, callback: ServiceCallback<AreaOfInterestResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestInStreamWithHttpOperationResponse
    name: 'getAreaOfInterestInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione restituisce un rettangolo attorno all'area più importante dell'immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function getAreaOfInterestInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.AreaOfInterestResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getAreaOfInterestWithHttpOperationResponse
    name: 'getAreaOfInterestWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione restituisce un rettangolo attorno all'area più importante dell'immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta contiene un codice di errore e un messaggio per determinare la causa dell'errore.
      In caso di errore, il codice di errore e un messaggio di errore vengono restituiti. Il codice di errore potrebbe essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, FailedToProcess, Timeout o errore.
    syntax:
      content: 'function getAreaOfInterestWithHttpOperationResponse(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.AreaOfInterestResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getPackageJsonInfo
    name: getPackageJsonInfo(string)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Tenta di individuare package. JSON per il pacchetto specificato nodejs per azure.
      Se trovato, restituisce il nome e la versione del pacchetto, vedere il file package. JSON se package. JSON non viene trovato, restituisce un valore predefinito.
    syntax:
      content: 'function getPackageJsonInfo(managementClientDir: string)'
      parameters:
        - id: managementClientDir
          type:
            - string
          description: passare la directory del client di gestione di azure specifico.
      return:
        type:
          - Object
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult
    name: 'getReadOperationResult(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: Questa interfaccia viene utilizzata per ottenere i risultati di riconoscimento dell'operazione di lettura. L'URL per questa interfaccia deve essere recuperato dal campo "Operation-Location" restituito dall'interfaccia di leggere il File Batch.
    syntax:
      content: 'function getReadOperationResult(operationId: string, options?: Object)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            ID dell'operazione di lettura restituite nella risposta dell'interfaccia "Leggere il File Batch".
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_2
    name: 'getReadOperationResult(string, Object, ServiceCallback<ReadOperationResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: Questa interfaccia viene utilizzata per ottenere i risultati di riconoscimento dell'operazione di lettura. L'URL per questa interfaccia deve essere recuperato dal campo "Operation-Location" restituito dall'interfaccia di leggere il File Batch.
    syntax:
      content: 'function getReadOperationResult(operationId: string, options: Object, callback: ServiceCallback<ReadOperationResult>)'
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ReadOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResult_1
    name: 'getReadOperationResult(string, ServiceCallback<ReadOperationResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: Questa interfaccia viene utilizzata per ottenere i risultati di riconoscimento dell'operazione di lettura. L'URL per questa interfaccia deve essere recuperato dal campo "Operation-Location" restituito dall'interfaccia di leggere il File Batch.
    syntax:
      content: 'function getReadOperationResult(operationId: string, callback: ServiceCallback<ReadOperationResult>)'
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ReadOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getReadOperationResultWithHttpOperationResponse
    name: 'getReadOperationResultWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: Questa interfaccia viene utilizzata per ottenere i risultati di riconoscimento dell'operazione di lettura. L'URL per questa interfaccia deve essere recuperato dal campo "Operation-Location" restituito dall'interfaccia di leggere il File Batch.
    syntax:
      content: 'function getReadOperationResultWithHttpOperationResponse(operationId: string, options?: Object)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            ID dell'operazione di lettura restituite nella risposta dell'interfaccia "Leggere il File Batch".
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ReadOperationResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult
    name: 'getTextOperationResult(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: Questa interfaccia viene utilizzata per ottenere il risultato dell'operazione di testo. L'URL per questa interfaccia deve essere recuperato dal campo 'Operation-Location' restituito dall'interfaccia di riconoscere il testo.
    syntax:
      content: 'function getTextOperationResult(operationId: string, options?: Object)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            ID dell'operazione di testo restituito nella risposta del 'Riconosce testo'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_2
    name: 'getTextOperationResult(string, Object, ServiceCallback<TextOperationResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: Questa interfaccia viene utilizzata per ottenere il risultato dell'operazione di testo. L'URL per questa interfaccia deve essere recuperato dal campo 'Operation-Location' restituito dall'interfaccia di riconoscere il testo.
    syntax:
      content: 'function getTextOperationResult(operationId: string, options: Object, callback: ServiceCallback<TextOperationResult>)'
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResult_1
    name: 'getTextOperationResult(string, ServiceCallback<TextOperationResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: Questa interfaccia viene utilizzata per ottenere il risultato dell'operazione di testo. L'URL per questa interfaccia deve essere recuperato dal campo 'Operation-Location' restituito dall'interfaccia di riconoscere il testo.
    syntax:
      content: 'function getTextOperationResult(operationId: string, callback: ServiceCallback<TextOperationResult>)'
      parameters:
        - id: operationId
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TextOperationResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.getTextOperationResultWithHttpOperationResponse
    name: 'getTextOperationResultWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: Questa interfaccia viene utilizzata per ottenere il risultato dell'operazione di testo. L'URL per questa interfaccia deve essere recuperato dal campo 'Operation-Location' restituito dall'interfaccia di riconoscere il testo.
    syntax:
      content: 'function getTextOperationResultWithHttpOperationResponse(operationId: string, options?: Object)'
      parameters:
        - id: operationId
          type:
            - string
          description: |
            ID dell'operazione di testo restituito nella risposta del 'Riconosce testo'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels
    name: listModels(Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione restituisce l'elenco di modelli specifici di dominio che sono supportati per l'API visione artificiale. L'API supporta attualmente i modelli specifici di dominio: riconoscimento di celebrità, riconoscimento di luoghi di interesse.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function listModels(options?: Object)'
      parameters:
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels_2
    name: 'listModels(Object, ServiceCallback<ListModelsResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione restituisce l'elenco di modelli specifici di dominio che sono supportati per l'API visione artificiale. L'API supporta attualmente i modelli specifici di dominio: riconoscimento di celebrità, riconoscimento di luoghi di interesse.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function listModels(options: Object, callback: ServiceCallback<ListModelsResult>)'
      parameters:
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModels_1
    name: listModels(ServiceCallback<ListModelsResult>)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione restituisce l'elenco di modelli specifici di dominio che sono supportati per l'API visione artificiale. L'API supporta attualmente i modelli specifici di dominio: riconoscimento di celebrità, riconoscimento di luoghi di interesse.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function listModels(callback: ServiceCallback<ListModelsResult>)'
      parameters:
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.ListModelsResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.listModelsWithHttpOperationResponse
    name: listModelsWithHttpOperationResponse(Object)
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione restituisce l'elenco di modelli specifici di dominio che sono supportati per l'API visione artificiale. L'API supporta attualmente i modelli specifici di dominio: riconoscimento di celebrità, riconoscimento di luoghi di interesse.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function listModelsWithHttpOperationResponse(options?: Object)'
      parameters:
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText
    name: 'recognizePrintedText(boolean, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Riconoscimento ottico dei caratteri (OCR) rileva il testo in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.
      Al termine dell'operazione, verranno restituiti i risultati di OCR.
      In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
    syntax:
      content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options?: Object)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: |
            Possibilità di rilevare l'orientamento del testo nell'immagine. Con detectOrientation = true di OCR servizio prova a rilevare l'orientamento dell'immagine e correggere l'errore prima dell'ulteriore elaborazione (ad esempio, se è capovolto).
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_2
    name: 'recognizePrintedText(boolean, string, Object, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Riconoscimento ottico dei caratteri (OCR) rileva il testo in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.
      Al termine dell'operazione, verranno restituiti i risultati di OCR.
      In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
    syntax:
      content: 'function recognizePrintedText(detectOrientation: boolean, url: string, options: Object, callback: ServiceCallback<OcrResult>)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedText_1
    name: 'recognizePrintedText(boolean, string, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Riconoscimento ottico dei caratteri (OCR) rileva il testo in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.
      Al termine dell'operazione, verranno restituiti i risultati di OCR.
      In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
    syntax:
      content: 'function recognizePrintedText(detectOrientation: boolean, url: string, callback: ServiceCallback<OcrResult>)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream
    name: 'recognizePrintedTextInStream(boolean, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Riconoscimento ottico dei caratteri (OCR) rileva il testo in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.
      Al termine dell'operazione, verranno restituiti i risultati di OCR.
      In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
    syntax:
      content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options?: Object)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: |
            Possibilità di rilevare l'orientamento del testo nell'immagine. Con detectOrientation = true di OCR servizio prova a rilevare l'orientamento dell'immagine e correggere l'errore prima dell'ulteriore elaborazione (ad esempio, se è capovolto).
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_2
    name: 'recognizePrintedTextInStream(boolean, stream.Readable, Object, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Riconoscimento ottico dei caratteri (OCR) rileva il testo in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.
      Al termine dell'operazione, verranno restituiti i risultati di OCR.
      In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
    syntax:
      content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, options: Object, callback: ServiceCallback<OcrResult>)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStream_1
    name: 'recognizePrintedTextInStream(boolean, stream.Readable, ServiceCallback<OcrResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Riconoscimento ottico dei caratteri (OCR) rileva il testo in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.
      Al termine dell'operazione, verranno restituiti i risultati di OCR.
      In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
    syntax:
      content: 'function recognizePrintedTextInStream(detectOrientation: boolean, image: stream.Readable, callback: ServiceCallback<OcrResult>)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: ''
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.OcrResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextInStreamWithHttpOperationResponse
    name: 'recognizePrintedTextInStreamWithHttpOperationResponse(boolean, stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Riconoscimento ottico dei caratteri (OCR) rileva il testo in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.
      Al termine dell'operazione, verranno restituiti i risultati di OCR.
      In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
    syntax:
      content: 'function recognizePrintedTextInStreamWithHttpOperationResponse(detectOrientation: boolean, image: stream.Readable, options?: Object)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: |
            Possibilità di rilevare l'orientamento del testo nell'immagine. Con detectOrientation = true di OCR servizio prova a rilevare l'orientamento dell'immagine e correggere l'errore prima dell'ulteriore elaborazione (ad esempio, se è capovolto).
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizePrintedTextWithHttpOperationResponse
    name: 'recognizePrintedTextWithHttpOperationResponse(boolean, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Riconoscimento ottico dei caratteri (OCR) rileva il testo in un'immagine ed estrae i caratteri riconosciuti in un flusso utilizzabile da computer.
      Al termine dell'operazione, verranno restituiti i risultati di OCR.
      In caso di errore, verrà restituito il codice di errore insieme a un messaggio di errore. Il codice di errore può essere uno dei InvalidImageUrl, InvalidImageFormat, InvalidImageSize, NotSupportedImage, NotSupportedLanguage o errore.
    syntax:
      content: 'function recognizePrintedTextWithHttpOperationResponse(detectOrientation: boolean, url: string, options?: Object)'
      parameters:
        - id: detectOrientation
          type:
            - boolean
          description: |
            Possibilità di rilevare l'orientamento del testo nell'immagine. Con detectOrientation = true di OCR servizio prova a rilevare l'orientamento dell'immagine e correggere l'errore prima dell'ulteriore elaborazione (ad esempio, se è capovolto).
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText
    name: 'recognizeText(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Riconoscere l''operazione del testo. Quando si usa l''interfaccia di riconoscere il testo, la risposta contiene un campo denominato ''Operation-Location''. Il campo ''Operation-Location'' contiene l''URL che è necessario usare per l''operazione Ottieni riconoscere testo il risultato dell''operazione.'
    syntax:
      content: 'function recognizeText(url: string, mode: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: mode
          type:
            - string
          description: |
            Tipo di testo da riconoscere. I valori possibili sono: 'Scritto dall'utente', 'stampato'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_2
    name: 'recognizeText(string, string, Object, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Riconoscere l''operazione del testo. Quando si usa l''interfaccia di riconoscere il testo, la risposta contiene un campo denominato ''Operation-Location''. Il campo ''Operation-Location'' contiene l''URL che è necessario usare per l''operazione Ottieni riconoscere testo il risultato dell''operazione.'
    syntax:
      content: 'function recognizeText(url: string, mode: string, options: Object, callback: ServiceCallback<void>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeText_1
    name: 'recognizeText(string, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Riconoscere l''operazione del testo. Quando si usa l''interfaccia di riconoscere il testo, la risposta contiene un campo denominato ''Operation-Location''. Il campo ''Operation-Location'' contiene l''URL che è necessario usare per l''operazione Ottieni riconoscere testo il risultato dell''operazione.'
    syntax:
      content: 'function recognizeText(url: string, mode: string, callback: ServiceCallback<void>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream
    name: 'recognizeTextInStream(stream.Readable, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Riconoscere l''operazione del testo. Quando si usa l''interfaccia di riconoscere il testo, la risposta contiene un campo denominato ''Operation-Location''. Il campo ''Operation-Location'' contiene l''URL che è necessario usare per l''operazione Ottieni riconoscere testo il risultato dell''operazione.'
    syntax:
      content: 'function recognizeTextInStream(image: stream.Readable, mode: string, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: mode
          type:
            - string
          description: |
            Tipo di testo da riconoscere. I valori possibili sono: 'Scritto dall'utente', 'stampato'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_2
    name: 'recognizeTextInStream(stream.Readable, string, Object, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Riconoscere l''operazione del testo. Quando si usa l''interfaccia di riconoscere il testo, la risposta contiene un campo denominato ''Operation-Location''. Il campo ''Operation-Location'' contiene l''URL che è necessario usare per l''operazione Ottieni riconoscere testo il risultato dell''operazione.'
    syntax:
      content: 'function recognizeTextInStream(image: stream.Readable, mode: string, options: Object, callback: ServiceCallback<void>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStream_1
    name: 'recognizeTextInStream(stream.Readable, string, ServiceCallback<void>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Riconoscere l''operazione del testo. Quando si usa l''interfaccia di riconoscere il testo, la risposta contiene un campo denominato ''Operation-Location''. Il campo ''Operation-Location'' contiene l''URL che è necessario usare per l''operazione Ottieni riconoscere testo il risultato dell''operazione.'
    syntax:
      content: 'function recognizeTextInStream(image: stream.Readable, mode: string, callback: ServiceCallback<void>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: mode
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<void>
          description: ''
      return:
        type:
          - Promise<void>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextInStreamWithHttpOperationResponse
    name: 'recognizeTextInStreamWithHttpOperationResponse(stream.Readable, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Riconoscere l''operazione del testo. Quando si usa l''interfaccia di riconoscere il testo, la risposta contiene un campo denominato ''Operation-Location''. Il campo ''Operation-Location'' contiene l''URL che è necessario usare per l''operazione Ottieni riconoscere testo il risultato dell''operazione.'
    syntax:
      content: 'function recognizeTextInStreamWithHttpOperationResponse(image: stream.Readable, mode: string, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: mode
          type:
            - string
          description: |
            Tipo di testo da riconoscere. I valori possibili sono: 'Scritto dall'utente', 'stampato'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.recognizeTextWithHttpOperationResponse
    name: 'recognizeTextWithHttpOperationResponse(string, string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: 'Riconoscere l''operazione del testo. Quando si usa l''interfaccia di riconoscere il testo, la risposta contiene un campo denominato ''Operation-Location''. Il campo ''Operation-Location'' contiene l''URL che è necessario usare per l''operazione Ottieni riconoscere testo il risultato dell''operazione.'
    syntax:
      content: 'function recognizeTextWithHttpOperationResponse(url: string, mode: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: mode
          type:
            - string
          description: |
            Tipo di testo da riconoscere. I valori possibili sono: 'Scritto dall'utente', 'stampato'
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<void>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.sendRequest_1
    name: sendRequest(PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions)
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function sendRequest<TResult>(options: PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions)'
      parameters:
        - id: options
          type:
            - PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions
          description: ''
      return:
        type:
          - Promise<TResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.sendRequest
    name: 'sendRequest(PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions, ServiceCallback<TResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function sendRequest<TResult>(options: PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions, callback: ServiceCallback<TResult>)'
      parameters:
        - id: options
          type:
            - PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions
          description: ''
        - id: callback
          type:
            - ServiceCallback<TResult>
          description: ''
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.sendRequestWithHttpOperationResponse
    name: sendRequestWithHttpOperationResponse(PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions)
    children: []
    type: method
    langs:
      - typeScript
    summary: ''
    syntax:
      content: 'function sendRequestWithHttpOperationResponse<TResult>(options: PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions)'
      parameters:
        - id: options
          type:
            - PathTemplateBasedRequestPrepareOptions | UrlBasedRequestPrepareOptions
          description: ''
      return:
        type:
          - Promise<HttpOperationResponse<TResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage
    name: 'tagImage(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function tagImage(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_2
    name: 'tagImage(string, Object, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function tagImage(url: string, options: Object, callback: ServiceCallback<TagResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImage_1
    name: 'tagImage(string, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function tagImage(url: string, callback: ServiceCallback<TagResult>)'
      parameters:
        - id: url
          type:
            - string
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream
    name: 'tagImageInStream(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function tagImageInStream(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_2
    name: 'tagImageInStream(stream.Readable, Object, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function tagImageInStream(image: stream.Readable, options: Object, callback: ServiceCallback<TagResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: options
          type:
            - Object
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStream_1
    name: 'tagImageInStream(stream.Readable, ServiceCallback<TagResult>)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function tagImageInStream(image: stream.Readable, callback: ServiceCallback<TagResult>)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: ''
        - id: callback
          type:
            - ServiceCallback<azure-cognitiveservices-computervision.TagResult>
          description: ''
      return:
        type:
          - Promise<azure-cognitiveservices-computervision.TagResult>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageInStreamWithHttpOperationResponse
    name: 'tagImageInStreamWithHttpOperationResponse(stream.Readable, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function tagImageInStreamWithHttpOperationResponse(image: stream.Readable, options?: Object)'
      parameters:
        - id: image
          type:
            - stream.Readable
          description: |
            Un flusso dell'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    package: azure-cognitiveservices-computervision
  - uid: azure-cognitiveservices-computervision.ComputerVisionClient.tagImageWithHttpOperationResponse
    name: 'tagImageWithHttpOperationResponse(string, Object)'
    children: []
    type: method
    langs:
      - typeScript
    summary: |-
      Questa operazione genera un elenco di parole o tag, che sono rilevanti per il contenuto dell'immagine specificato. L'API visione artificiale può restituire i tag in base agli oggetti, che vive esseri, panorami e azioni trovate nelle immagini. A differenza delle categorie, i tag non sono organizzati in base a un sistema di classificazione gerarchica, ma corrispondono al contenuto dell'immagine. I tag possono contenere gli hint per evitare ambiguità o fornire un contesto, ad esempio il cello"tag" può essere accompagnata dall'hint "strumento musicale". Tutti i tag sono in inglese.
      Sono supportati due metodi di input: (1) caricare un'immagine o (2) specificando un URL immagine.
      Una risposta con esito positivo verrà restituita in formato JSON. Se la richiesta ha esito negativo, la risposta conterrà un codice di errore e un messaggio per consentire di comprendere la causa dell'errore.
    syntax:
      content: 'function tagImageWithHttpOperationResponse(url: string, options?: Object)'
      parameters:
        - id: url
          type:
            - string
          description: |
            Raggiungibile pubblicamente URL di un'immagine.
        - id: options
          type:
            - Object
          description: ''
          optional: true
      return:
        type:
          - Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    package: azure-cognitiveservices-computervision
references:
  - uid: Promise<azure-cognitiveservices-computervision.ImageAnalysis>
    name: ImageAnalysis>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ImageAnalysis>
    name: ImageAnalysis>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>'
        fullName: '>'
  - uid: Promise<azure-cognitiveservices-computervision.DomainModelResults>
    name: DomainModelResults>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.DomainModelResults>
    name: DomainModelResults>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DomainModelResults>>
    name: DomainModelResults>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: DomainModelResults
        fullName: DomainModelResults
        uid: azure-cognitiveservices-computervision.DomainModelResults
      - name: '>>'
        fullName: '>>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageAnalysis>>
    name: ImageAnalysis>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ImageAnalysis
        fullName: ImageAnalysis
        uid: azure-cognitiveservices-computervision.ImageAnalysis
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ImageDescription>
    name: ImageDescription>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ImageDescription>
    name: ImageDescription>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ImageDescription>>
    name: ImageDescription>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ImageDescription
        fullName: ImageDescription
        uid: azure-cognitiveservices-computervision.ImageDescription
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.DetectResult>
    name: DetectResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: DetectResult
        fullName: DetectResult
        uid: azure-cognitiveservices-computervision.DetectResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.DetectResult>
    name: DetectResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: DetectResult
        fullName: DetectResult
        uid: azure-cognitiveservices-computervision.DetectResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.DetectResult>>
    name: DetectResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: DetectResult
        fullName: DetectResult
        uid: azure-cognitiveservices-computervision.DetectResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.AreaOfInterestResult>
    name: AreaOfInterestResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: AreaOfInterestResult
        fullName: AreaOfInterestResult
        uid: azure-cognitiveservices-computervision.AreaOfInterestResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.AreaOfInterestResult>
    name: AreaOfInterestResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: AreaOfInterestResult
        fullName: AreaOfInterestResult
        uid: azure-cognitiveservices-computervision.AreaOfInterestResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.AreaOfInterestResult>>
    name: AreaOfInterestResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: AreaOfInterestResult
        fullName: AreaOfInterestResult
        uid: azure-cognitiveservices-computervision.AreaOfInterestResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ReadOperationResult>
    name: ReadOperationResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ReadOperationResult
        fullName: ReadOperationResult
        uid: azure-cognitiveservices-computervision.ReadOperationResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ReadOperationResult>
    name: ReadOperationResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ReadOperationResult
        fullName: ReadOperationResult
        uid: azure-cognitiveservices-computervision.ReadOperationResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ReadOperationResult>>
    name: ReadOperationResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ReadOperationResult
        fullName: ReadOperationResult
        uid: azure-cognitiveservices-computervision.ReadOperationResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.TextOperationResult>
    name: TextOperationResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.TextOperationResult>
    name: TextOperationResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TextOperationResult>>
    name: TextOperationResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: TextOperationResult
        fullName: TextOperationResult
        uid: azure-cognitiveservices-computervision.TextOperationResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.ListModelsResult>
    name: ListModelsResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.ListModelsResult>
    name: ListModelsResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.ListModelsResult>>
    name: ListModelsResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: ListModelsResult
        fullName: ListModelsResult
        uid: azure-cognitiveservices-computervision.ListModelsResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.OcrResult>
    name: OcrResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.OcrResult>
    name: OcrResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.OcrResult>>
    name: OcrResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: OcrResult
        fullName: OcrResult
        uid: azure-cognitiveservices-computervision.OcrResult
      - name: '>>'
        fullName: '>>'
  - uid: Promise<azure-cognitiveservices-computervision.TagResult>
    name: TagResult>
    spec.typeScript:
      - name: Promise<
        fullName: Promise<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>'
        fullName: '>'
  - uid: ServiceCallback<azure-cognitiveservices-computervision.TagResult>
    name: TagResult>
    spec.typeScript:
      - name: ServiceCallback<
        fullName: ServiceCallback<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>'
        fullName: '>'
  - uid: Promise<HttpOperationResponse<azure-cognitiveservices-computervision.TagResult>>
    name: TagResult>>
    spec.typeScript:
      - name: Promise<HttpOperationResponse<
        fullName: Promise<HttpOperationResponse<
      - name: TagResult
        fullName: TagResult
        uid: azure-cognitiveservices-computervision.TagResult
      - name: '>>'
        fullName: '>>'